{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "#import torch \n",
    "import copy\n",
    "import dill\n",
    "from sklearn.base import BaseEstimator\n",
    "from lightgbm import LGBMRegressor\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot  as plt\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Convert to csv***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "    data = data.replace('\\t', ',')\n",
    "    data = 'UserId,FilmId,Mark\\n' + data\n",
    "with open('train.csv', 'w') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "    data = data.replace('\\t', ',')\n",
    "    data = 'UserId,FilmId\\n' + data\n",
    "with open('test.csv', 'w') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Load Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw  = pd.read_csv('test.csv')\n",
    "train_raw = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>FilmId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  FilmId\n",
       "0       1      20\n",
       "1       1      33\n",
       "2       1      61\n",
       "3       1     117\n",
       "4       1     155"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>FilmId</th>\n",
       "      <th>Mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserId  FilmId  Mark\n",
       "0       1       1     5\n",
       "1       1       2     3\n",
       "2       1       3     4\n",
       "3       1       4     3\n",
       "4       1       5     3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Write Submission***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission(name_of_file, prediction):\n",
    "    df = pd.DataFrame()\n",
    "    df['Id'] = np.arange(1, len(test_raw) + 1)\n",
    "    df['Score'] = prediction\n",
    "    df.to_csv(name_of_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Convert to sparse matrix for ALS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_sparse(df):\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "    for d in range(len(df.index)):\n",
    "        cur_data = df.iloc[d]\n",
    "        rows.append(cur_data['UserId'])\n",
    "        cols.append(cur_data['FilmId'])\n",
    "        if 'Mark' in cur_data:\n",
    "            data.append(cur_data['Mark'])\n",
    "        else:\n",
    "            data.append(1)\n",
    "    return sp.csr_matrix((data, (rows, cols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ImplicitALS without bias***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImplicitALS:\n",
    "    def __init__(self, lambda1=1, lambda2=1, \n",
    "                 n_epochs=35, latent_dim=3,\n",
    "                 user_size=944, item_size=1683):\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.n_epochs = n_epochs\n",
    "        self.latent_dim = latent_dim\n",
    "        self.user_size = user_size\n",
    "        self.item_size = item_size\n",
    "        self.X = np.random.randn(self.user_size, self.latent_dim)\n",
    "        self.Y = np.random.randn(self.item_size, self.latent_dim)\n",
    "        self.beta = np.random.randn(self.user_size)\n",
    "        self.gamma = np.random.randn(self.item_size)\n",
    "        self.mu = 0\n",
    "        self.C = np.zeros((self.user_size, self.item_size))\n",
    "        self.R = np.zeros((self.user_size, self.item_size))\n",
    "        self.users = set()\n",
    "        self.items = set()\n",
    "        self.mses = []\n",
    "    \n",
    "    def describe(self):\n",
    "        return 'unbiased_als ' + str([self.lambda1, self.lambda2, self.latent_dim, self.n_epochs])\n",
    "    \n",
    "    def fit(self, train_data, train_marks, eval_set=None, verbose=False):\n",
    "        self.mu = np.mean(train_marks)\n",
    "        self.R[train_data['UserId'], train_data['FilmId']] = train_marks\n",
    "        self.C[train_data['UserId'], train_data['FilmId']] = 1.0\n",
    "        \n",
    "        self.users = set(train_data['UserId'])\n",
    "        self.items = set(train_data['FilmId'])\n",
    "        \n",
    "        masks_i = [self.R[:, i] > 0 for i in range(self.item_size)]\n",
    "        masks_u = [self.R[u, :] > 0 for u in range(self.user_size)]\n",
    "        \n",
    "        nonzero_i = [np.sum(self.R[:, i] > 0) for i in range(self.item_size)]\n",
    "        nonzero_u = [np.sum(self.R[u, :] > 0) for u in range(self.user_size)]\n",
    "        I = np.eye(self.latent_dim, self.latent_dim)\n",
    "        if verbose:\n",
    "            range_epochs = tqdm.tqdm(range(self.n_epochs))\n",
    "        else:\n",
    "            range_epochs = range(self.n_epochs)\n",
    "        for j in range_epochs:\n",
    "            \n",
    "            #item step\n",
    "            for i in range(self.item_size):\n",
    "                \n",
    "                if nonzero_i[i] == 0:\n",
    "                    continue\n",
    "                \n",
    "                mask = masks_i[i]\n",
    "                C_i = self.C[mask, i]\n",
    "                X_i = self.X[mask]\n",
    "                p_i = self.R[mask, i]\n",
    "                X_iT = X_i.T\n",
    "                d_i = C_i*p_i\n",
    "                INV = np.linalg.inv(np.dot(X_iT*C_i, X_i) + self.lambda1*I)\n",
    "                self.Y[i, :] = np.dot(INV, np.dot(X_iT, d_i))\n",
    "            \n",
    "            #user step            \n",
    "            for u in range(self.user_size):\n",
    "                \n",
    "                if nonzero_u[u] == 0:\n",
    "                    continue\n",
    "                \n",
    "                mask = masks_u[u]\n",
    "                C_u = self.C[u, mask]\n",
    "                Y_u = self.Y[mask]\n",
    "                p_u = self.R[u, mask]\n",
    "                Y_uT = Y_u.T\n",
    "                d_u = C_u*p_u\n",
    "                INV = np.linalg.inv(np.dot(Y_uT*C_u, Y_u) + self.lambda2*I)\n",
    "                self.X[u, :] = np.dot(INV, np.dot(Y_uT, d_u))\n",
    "            \n",
    "            if verbose:\n",
    "                clear_output(True)\n",
    "                predictions = np.dot(self.X, self.Y.T)\n",
    "                print(mean_squared_error(predictions[train_data['UserId'], train_data['FilmId']], train_marks))\n",
    "                if not eval_set is None:\n",
    "                    test_data = eval_set[0]\n",
    "                    test_marks = eval_set[1]\n",
    "                    prediction = predictions[test_data['UserId'], test_data['FilmId']]\n",
    "                    mask_ = [not(u in self.users and i in self.items) for u, i in zip(test_data['UserId'], test_data['FilmId'])]\n",
    "                    prediction[mask_] = 2.5\n",
    "                    print(mean_squared_error(prediction, test_marks))\n",
    "                \n",
    "    def predict(self, test_data):\n",
    "        predictions = np.dot(self.X, self.Y.T)\n",
    "        prediction = predictions[test_data['UserId'], test_data['FilmId']]\n",
    "        mask_ = [not(u in self.users and i in self.items) for u, i in zip(test_data['UserId'], test_data['FilmId'])]\n",
    "        prediction[mask_] = 2.5\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Implicit ALS with bias***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImplicitALSBiased:\n",
    "    def __init__(self, lambda1=1, lambda2=1, \n",
    "                 n_epochs=35, latent_dim=3,\n",
    "                 user_size=944, item_size=1683):\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "        self.n_epochs = n_epochs\n",
    "        self.latent_dim = latent_dim\n",
    "        self.user_size = user_size\n",
    "        self.item_size = item_size\n",
    "        self.X = np.random.randn(self.user_size, self.latent_dim + 2)\n",
    "        self.Y = np.random.randn(self.item_size, self.latent_dim + 2)\n",
    "        ####################\n",
    "        self.X[:, 0] = 1.0\n",
    "        self.Y[:, -1] = 1.0\n",
    "        ####################        \n",
    "        self.beta = 0.1*np.random.randn(self.user_size)\n",
    "        self.gamma = 0.1*np.random.randn(self.item_size)\n",
    "        self.mu = 0\n",
    "        self.C = np.zeros((self.user_size, self.item_size))\n",
    "        self.R = np.zeros((self.user_size, self.item_size))\n",
    "        self.users = set()\n",
    "        self.items = set()\n",
    "        self.mses = []\n",
    "    \n",
    "    def describe(self):\n",
    "        return 'biased_als ' + str([self.lambda1, self.lambda2, self.latent_dim, self.latent_dim])\n",
    "    \n",
    "    def fit(self, train_data, train_marks, eval_set=None, C=None, verbose=False):\n",
    "        \n",
    "        self.mu = np.mean(train_marks)\n",
    "        \n",
    "        self.R[train_data['UserId'], train_data['FilmId']] = train_marks\n",
    "        if C is None:\n",
    "            self.C[train_data['UserId'], train_data['FilmId']] = 1.0\n",
    "        else:\n",
    "            self.C[train_data['UserId'], train_data['FilmId']] = C\n",
    "        \n",
    "        self.users = set(train_data['UserId'])\n",
    "        self.items = set(train_data['FilmId'])\n",
    "        \n",
    "        masks_i = [self.R[:, i] > 0 for i in range(self.item_size)]\n",
    "        masks_u = [self.R[u, :] > 0 for u in range(self.user_size)]\n",
    "        \n",
    "        nonzero_i = [np.sum(self.R[:, i] > 0) for i in range(self.item_size)]\n",
    "        nonzero_u = [np.sum(self.R[u, :] > 0) for u in range(self.user_size)]\n",
    "        \n",
    "        I = np.eye(self.latent_dim + 1, self.latent_dim + 1)\n",
    "        \n",
    "        if verbose:\n",
    "            range_epochs = tqdm.tqdm(range(self.n_epochs))\n",
    "        else:\n",
    "            range_epochs = range(self.n_epochs)\n",
    "            \n",
    "        \n",
    "        for j in range_epochs:\n",
    "            \n",
    "            #item step\n",
    "            for i in range(self.item_size):\n",
    "                \n",
    "                if nonzero_i[i] == 0:\n",
    "                    continue\n",
    "                \n",
    "                mask = masks_i[i]\n",
    "                C_i = self.C[mask, i]\n",
    "                X_i = self.X[mask, :-1]\n",
    "                p_i = self.R[mask, i] - self.X[mask, -1] - self.mu\n",
    "                X_iT = X_i.T\n",
    "                d_i = C_i*p_i\n",
    "                INV = np.linalg.inv(np.dot(X_iT*C_i, X_i) + self.lambda1*I)\n",
    "                self.Y[i, :-1] = np.dot(INV, np.dot(X_iT, d_i))\n",
    "            \n",
    "            #user step            \n",
    "            for u in range(self.user_size):\n",
    "                \n",
    "                if nonzero_u[u] == 0:\n",
    "                    continue\n",
    "                \n",
    "                mask = masks_u[u]\n",
    "                C_u = self.C[u, mask]\n",
    "                Y_u = self.Y[mask, 1:]\n",
    "                p_u = self.R[u, mask] - self.Y[mask, 0] - self.mu\n",
    "                Y_uT = Y_u.T\n",
    "                d_u = C_u*p_u\n",
    "                INV = np.linalg.inv(np.dot(Y_uT*C_u, Y_u) + self.lambda2*I)\n",
    "                self.X[u, 1:] = np.dot(INV, np.dot(Y_uT, d_u))\n",
    "            \n",
    "            if verbose:\n",
    "                clear_output(True)\n",
    "                predictions = np.dot(self.X, self.Y.T)\n",
    "                print(mean_squared_error(self.mu + predictions[train_data['UserId'], train_data['FilmId']], train_marks))\n",
    "                if not eval_set is None:\n",
    "                    test_data = eval_set[0]\n",
    "                    test_marks = eval_set[1]\n",
    "                    prediction = self.mu + predictions[test_data['UserId'], test_data['FilmId']]\n",
    "                    mask_ = [not(u in self.users and i in self.items) for u, i in zip(test_data['UserId'], test_data['FilmId'])]\n",
    "                    prediction[mask_] = self.mu\n",
    "                    mask_ = [u not in self.users and i in self.items for u, i in zip(test_data['UserId'], test_data['FilmId'])]\n",
    "                    prediction[mask_] = self.mu + self.Y[test_data['FilmId'][mask_], 0]\n",
    "                    mask_ = [u in self.users and i not in self.items for u, i in zip(test_data['UserId'], test_data['FilmId'])]\n",
    "                    prediction[mask_] = self.mu + self.X[test_data['UserId'][mask_], -1]\n",
    "                    print(mean_squared_error(prediction, test_marks))\n",
    "                \n",
    "    def predict(self, test_data):\n",
    "        predictions = np.dot(self.X, self.Y.T)\n",
    "        prediction = self.mu + predictions[test_data['UserId'], test_data['FilmId']]\n",
    "        mask_ = [not(u in self.users and i in self.items) for u, i in zip(test_data['UserId'], test_data['FilmId'])]\n",
    "        prediction[mask_] = self.mu\n",
    "        mask_ = [u not in self.users and i in self.items for u, i in zip(test_data['UserId'], test_data['FilmId'])]\n",
    "        prediction[mask_] = self.mu + self.Y[test_data['FilmId'][mask_], 0]\n",
    "        mask_ = [u in self.users and i not in self.items for u, i in zip(test_data['UserId'], test_data['FilmId'])]\n",
    "        prediction[mask_] = self.mu + self.X[test_data['UserId'][mask_], -1]\n",
    "        return prediction\n",
    "    \n",
    "    def predict_semisupervise(self, test_data):\n",
    "        predictions = np.dot(self.X, self.Y.T)\n",
    "        prediction = self.mu + predictions[test_data['UserId'], test_data['FilmId']]\n",
    "        mask_ = [not(u in self.users or i in self.items) for u, i in zip(test_data['UserId'], test_data['FilmId'])]\n",
    "        return prediction, mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(i):\n",
    "    if i < 10:\n",
    "        return 0.95\n",
    "    elif i < 25:\n",
    "        return 0.9\n",
    "    elif i < 40:\n",
    "        return 0.75\n",
    "    elif i < 100:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemiSuperviseIALS:\n",
    "    def __init__(self, ss_ials):\n",
    "        self.models = copy.deepcopy(ss_ials)\n",
    "        self.implicit_models = None\n",
    "        self.explicit_models = None\n",
    "    \n",
    "    def describe(self):\n",
    "        return 'ss_ials ' + self.models[0].describe()\n",
    "    \n",
    "    def fit(self, n_added, train_data, train_marks, test_data, verbose=False):\n",
    "        explicit_models = copy.deepcopy(self.models)\n",
    "        predictions = []\n",
    "        C = np.ones(train_marks.shape[0])\n",
    "        if verbose:\n",
    "            range_models = tqdm.tqdm(range(len(explicit_models)))\n",
    "        else:\n",
    "            range_models = range(len(explicit_models))\n",
    "        for i in range_models:\n",
    "            new_index = np.random.permutation(train_marks.shape[0])[:-1000]\n",
    "            explicit_models[i].fit(train_data.iloc[new_index], train_marks.iloc[new_index])\n",
    "            cur_pred, cur_mask = explicit_models[i].predict_semisupervise(test_data)\n",
    "            predictions.append(cur_pred)\n",
    "        self.explicit_models = explicit_models\n",
    "        predictions = np.array(predictions) \n",
    "        predictions_vars = np.var(predictions, axis=0)\n",
    "        predictions_old = np.array(predictions)\n",
    "        predictions = np.mean(predictions, axis=0)\n",
    "        args = np.argsort(predictions_vars)[:n_added]\n",
    "        candidates = test_data.iloc[args]\n",
    "        candidates_marks = pd.DataFrame(predictions[args])\n",
    "        new_train_marks = pd.concat((train_marks, candidates_marks), axis=0).squeeze(1)\n",
    "        new_train_data = pd.concat((train_data, candidates), axis=0)\n",
    "        C = np.concatenate((C, np.array([func(i) for i in range(n_added)])))\n",
    "        self.implicit_models = copy.deepcopy(self.models)\n",
    "        predictions = []\n",
    "        if verbose:\n",
    "            range_models = tqdm.tqdm(range(len(explicit_models)))\n",
    "        else:\n",
    "            range_models = range(len(explicit_models))\n",
    "        for i in range_models:\n",
    "            self.implicit_models[i].fit(new_train_data, new_train_marks, C=C)\n",
    "            #cur_pred = self.implicit_models[i].predict(test_data)\n",
    "            #predictions.append(cur_pred)\n",
    "        #predictions = np.array(predictions)\n",
    "        #predictions = np.mean(predictions, axis=0)\n",
    "        #return predictions, predictions_old\n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        predictions = []\n",
    "        for i in range(len(self.implicit_models)):\n",
    "            predictions.append(self.implicit_models[i].predict(test_data))\n",
    "            predictions.append(self.explicit_models[i].predict(test_data))\n",
    "        predictions = np.array(predictions)\n",
    "        return np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data):\n",
    "    model = copy.deepcopy(data[0])\n",
    "    train_raw = data[1]\n",
    "    test_raw = data[2]\n",
    "    model.fit(train_raw[['UserId', 'FilmId']], train_raw['Mark'])\n",
    "    prediction = model.predict(test_raw)\n",
    "    return {'model':model.describe(), 'test_prediction':prediction} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_model(data):\n",
    "    model = data[0]\n",
    "    train_raw = data[1]\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    prediction = np.zeros(train_raw.shape[0])\n",
    "    for train_index, test_index in kf.split(train_raw):\n",
    "        train_kf, test_kf = train_raw.iloc[train_index], train_raw.iloc[test_index]\n",
    "        model_kf = copy.deepcopy(model)\n",
    "        model_kf.fit(train_kf[['UserId', 'FilmId']], train_kf['Mark'])\n",
    "        cur_pred = model_kf.predict(test_kf[['UserId', 'FilmId']])\n",
    "        prediction[test_index] = cur_pred\n",
    "    return {'model':model.describe(), 'prediction':prediction}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_implicit_model(data):\n",
    "    model = copy.deepcopy(data[0])\n",
    "    train_raw = data[1]\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    prediction = np.zeros(train_raw.shape[0])\n",
    "    for train_index, test_index in kf.split(train_raw):\n",
    "        train_kf, test_kf = train_raw.iloc[train_index], train_raw.iloc[test_index]\n",
    "        model_kf = copy.deepcopy(model)\n",
    "        model_kf.fit(500, train_kf[['UserId', 'FilmId']], train_kf['Mark'], test_kf)\n",
    "        prediction[test_index] = model_kf.predict(test_kf)\n",
    "    return {'model':model.describe(), 'prediction':prediction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_implicit_model(data):\n",
    "    model = copy.deepcopy(data[0])\n",
    "    train_raw = data[1]\n",
    "    test_raw = data[2]\n",
    "    model.fit(500, train_raw[['UserId', 'FilmId']], train_raw['Mark'], test_raw)\n",
    "    prediction = model.predict(test_raw)\n",
    "    return {'model': model.describe(), 'test_prediction':prediction}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Explicit ALS stacking***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ImplicitALS(latent_dim=4, lambda1=7, lambda2=7, n_epochs=40),\n",
    "         ImplicitALS(latent_dim=4, lambda1=10, lambda2=10, n_epochs=40),\n",
    "         ImplicitALS(latent_dim=4, lambda1=12, lambda2=12, n_epochs=40),\n",
    "         ImplicitALS(latent_dim=5, lambda1=5, lambda2=5, n_epochs=40),\n",
    "         ImplicitALS(latent_dim=5, lambda1=7, lambda2=7, n_epochs=40),\n",
    "         ImplicitALS(latent_dim=5, lambda1=10, lambda2=10, n_epochs=40),\n",
    "         ImplicitALS(latent_dim=5, lambda1=12, lambda2=12, n_epochs=40),\n",
    "         ImplicitALS(latent_dim=6, lambda1=5, lambda2=5, n_epochs=40),\n",
    "         ImplicitALS(latent_dim=6, lambda1=7, lambda2=7, n_epochs=40),\n",
    "         ImplicitALS(latent_dim=6, lambda1=10, lambda2=10, n_epochs=40),####\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=5, lambda2=5, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=7, lambda2=7, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=10, lambda2=10, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=12, lambda2=12, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=5, lambda2=5, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=7, lambda2=7, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=10, lambda2=10, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=12, lambda2=12, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=5, lambda2=5, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=7, lambda2=7, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=10, lambda2=10, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=12, lambda2=12, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=15, lambda2=15, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=8, lambda1=12, lambda2=12, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=5, lambda2=5, n_epochs=65),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=7, lambda2=7, n_epochs=65),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=10, lambda2=10, n_epochs=65),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=12, lambda2=12, n_epochs=65),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=5, lambda2=5, n_epochs=65),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=7, lambda2=7, n_epochs=65),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=10, lambda2=10, n_epochs=65),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=12, lambda2=12, n_epochs=65),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=5, lambda2=5, n_epochs=65),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=7, lambda2=7, n_epochs=65),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=10, lambda2=10, n_epochs=65),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=12, lambda2=12, n_epochs=65),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=15, lambda2=15, n_epochs=65),\n",
    "         ImplicitALSBiased(latent_dim=8, lambda1=12, lambda2=12, n_epochs=65),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=5, lambda2=5, n_epochs=25),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=7, lambda2=7, n_epochs=25),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=10, lambda2=10, n_epochs=25),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=12, lambda2=12, n_epochs=25),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=5, lambda2=5, n_epochs=25),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=7, lambda2=7, n_epochs=25),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=10, lambda2=10, n_epochs=25),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=12, lambda2=12, n_epochs=25),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=5, lambda2=5, n_epochs=25),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=7, lambda2=7, n_epochs=25),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=10, lambda2=10, n_epochs=25),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=12, lambda2=12, n_epochs=25),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=15, lambda2=15, n_epochs=25),\n",
    "         ImplicitALSBiased(latent_dim=8, lambda1=12, lambda2=12, n_epochs=25),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=3, lambda2=5, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=5, lambda2=3, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=6, lambda2=10, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=4, lambda1=10, lambda2=6, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=12, lambda2=7, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=7, lambda2=12, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=14, lambda2=7, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=5, lambda1=7, lambda2=14, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=7, lambda2=5, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=5, lambda2=7, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=3, lambda2=10, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=10, lambda2=3, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=6, lambda1=15, lambda2=9, n_epochs=40),\n",
    "         ImplicitALSBiased(latent_dim=8, lambda1=9, lambda2=15, n_epochs=40)]\n",
    "additional_params = dill.load(open('params.dill', 'rb'))\n",
    "additional_models = [ImplicitALSBiased(latent_dim=p[2], lambda1=p[0], lambda2=p[1], n_epochs=p[3]) for p in additional_params]\n",
    "models.extend(additional_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(model, copy.deepcopy(train_raw)) for model in models]\n",
    "data_train = [(model, copy.deepcopy(train_raw), copy.deepcopy(test_raw)) for model in models]\n",
    "dill.dump(models, open('explicit_models.dill', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [41:17<00:00, 23.15s/it]\n"
     ]
    }
   ],
   "source": [
    "stacking_explicit = []\n",
    "for d in tqdm.tqdm(data):\n",
    "    stacking_explicit.append(stack_model(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(stacking_explicit, open('stacking_explicit.dill', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [09:08<00:00,  5.13s/it]\n"
     ]
    }
   ],
   "source": [
    "test_explicit = []\n",
    "for d in tqdm.tqdm(data_train):\n",
    "    test_explicit.append(train_model(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(test_explicit, open('test_explicit.dill', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Implicit ALS stacking***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sialses = [SemiSuperviseIALS([ImplicitALSBiased(latent_dim=3, lambda1=4, lambda2=4, n_epochs=45) for i in range(10)]),\n",
    "           SemiSuperviseIALS([ImplicitALSBiased(latent_dim=4, lambda1=4, lambda2=4, n_epochs=45) for i in range(10)]),\n",
    "           SemiSuperviseIALS([ImplicitALSBiased(latent_dim=4, lambda1=5, lambda2=5, n_epochs=45) for i in range(10)]),\n",
    "           SemiSuperviseIALS([ImplicitALSBiased(latent_dim=2, lambda1=4, lambda2=4, n_epochs=40) for i in range(10)]),\n",
    "           SemiSuperviseIALS([ImplicitALSBiased(latent_dim=5, lambda1=7, lambda2=7, n_epochs=40) for i in range(10)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_implicit = [(model, copy.deepcopy(train_raw)) for model in sialses]\n",
    "data_implicit_test = [(model, copy.deepcopy(train_raw), copy.deepcopy(test_raw)) for model in sialses]\n",
    "dill.dump(sialses, open('sialses.dill', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [32:46<00:00, 393.38s/it]\n"
     ]
    }
   ],
   "source": [
    "stacking_implicit = []\n",
    "for d in tqdm.tqdm(data_implicit):\n",
    "    stacking_implicit.append(stack_implicit_model(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(stacking_implicit, open('stacking_implicit.dill', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [08:33<00:00, 102.61s/it]\n"
     ]
    }
   ],
   "source": [
    "test_implicit = []\n",
    "for d in tqdm.tqdm(data_implicit_test):\n",
    "    test_implicit.append(train_implicit_model(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(test_implicit, open('test_implicit.dill', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Dataset for boosting***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_explicit = dill.load(open('stacking_explicit.dill', 'rb'))\n",
    "stacking_implicit = dill.load(open('stacking_implicit.dill', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "predictions = []\n",
    "for i in stacking_explicit:\n",
    "    model_names.append(i['model'])\n",
    "    predictions.append(i['prediction'])\n",
    "for i in stacking_implicit:\n",
    "    model_names.append(i['model'])\n",
    "    predictions.append(i['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stacked = pd.DataFrame(predictions, index = model_names).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_explicit = dill.load(open('test_explicit.dill', 'rb'))\n",
    "test_implicit = dill.load(open('test_implicit.dill', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = []\n",
    "predictions = []\n",
    "for i in test_explicit:\n",
    "    model_names.append(i['model'])\n",
    "    predictions.append(i['test_prediction'])\n",
    "for i in test_implicit:\n",
    "    model_names.append(i['model'])\n",
    "    predictions.append(i['test_prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stacked = pd.DataFrame(predictions, index = model_names).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unbiased_als [7, 7, 4, 40]</th>\n",
       "      <th>unbiased_als [10, 10, 4, 40]</th>\n",
       "      <th>unbiased_als [12, 12, 4, 40]</th>\n",
       "      <th>unbiased_als [5, 5, 5, 40]</th>\n",
       "      <th>unbiased_als [7, 7, 5, 40]</th>\n",
       "      <th>unbiased_als [10, 10, 5, 40]</th>\n",
       "      <th>unbiased_als [12, 12, 5, 40]</th>\n",
       "      <th>unbiased_als [5, 5, 6, 40]</th>\n",
       "      <th>unbiased_als [7, 7, 6, 40]</th>\n",
       "      <th>unbiased_als [10, 10, 6, 40]</th>\n",
       "      <th>...</th>\n",
       "      <th>biased_als [8, 8, 3, 3]</th>\n",
       "      <th>biased_als [5, 5, 4, 4]</th>\n",
       "      <th>biased_als [6, 6, 3, 3]</th>\n",
       "      <th>biased_als [10, 10, 4, 4]</th>\n",
       "      <th>biased_als [8, 8, 4, 4]</th>\n",
       "      <th>ss_ials biased_als [4, 4, 3, 3]</th>\n",
       "      <th>ss_ials biased_als [4, 4, 4, 4]</th>\n",
       "      <th>ss_ials biased_als [5, 5, 4, 4]</th>\n",
       "      <th>ss_ials biased_als [4, 4, 2, 2]</th>\n",
       "      <th>ss_ials biased_als [7, 7, 5, 5]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.592601</td>\n",
       "      <td>3.733556</td>\n",
       "      <td>3.696535</td>\n",
       "      <td>3.532348</td>\n",
       "      <td>3.524818</td>\n",
       "      <td>3.482530</td>\n",
       "      <td>3.491156</td>\n",
       "      <td>3.534645</td>\n",
       "      <td>3.923361</td>\n",
       "      <td>3.909867</td>\n",
       "      <td>...</td>\n",
       "      <td>3.288667</td>\n",
       "      <td>3.522192</td>\n",
       "      <td>3.353738</td>\n",
       "      <td>3.714608</td>\n",
       "      <td>3.701243</td>\n",
       "      <td>3.336324</td>\n",
       "      <td>3.467200</td>\n",
       "      <td>3.649741</td>\n",
       "      <td>3.841463</td>\n",
       "      <td>3.795175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.550760</td>\n",
       "      <td>3.509360</td>\n",
       "      <td>3.487067</td>\n",
       "      <td>3.521843</td>\n",
       "      <td>3.473323</td>\n",
       "      <td>3.392697</td>\n",
       "      <td>3.396442</td>\n",
       "      <td>3.519983</td>\n",
       "      <td>3.279215</td>\n",
       "      <td>3.286031</td>\n",
       "      <td>...</td>\n",
       "      <td>3.470855</td>\n",
       "      <td>3.281536</td>\n",
       "      <td>3.449982</td>\n",
       "      <td>3.391374</td>\n",
       "      <td>3.388822</td>\n",
       "      <td>3.442233</td>\n",
       "      <td>3.292226</td>\n",
       "      <td>3.300970</td>\n",
       "      <td>3.492179</td>\n",
       "      <td>3.306232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.054709</td>\n",
       "      <td>4.064456</td>\n",
       "      <td>4.011243</td>\n",
       "      <td>4.147824</td>\n",
       "      <td>4.066299</td>\n",
       "      <td>3.962364</td>\n",
       "      <td>3.932126</td>\n",
       "      <td>4.117941</td>\n",
       "      <td>4.062959</td>\n",
       "      <td>4.031632</td>\n",
       "      <td>...</td>\n",
       "      <td>3.830440</td>\n",
       "      <td>3.806959</td>\n",
       "      <td>3.849735</td>\n",
       "      <td>3.903995</td>\n",
       "      <td>3.892564</td>\n",
       "      <td>3.857864</td>\n",
       "      <td>3.790467</td>\n",
       "      <td>3.829250</td>\n",
       "      <td>4.021208</td>\n",
       "      <td>3.859430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.378575</td>\n",
       "      <td>3.349753</td>\n",
       "      <td>3.378884</td>\n",
       "      <td>3.397274</td>\n",
       "      <td>3.476615</td>\n",
       "      <td>3.327078</td>\n",
       "      <td>3.353676</td>\n",
       "      <td>3.401224</td>\n",
       "      <td>3.610752</td>\n",
       "      <td>3.567498</td>\n",
       "      <td>...</td>\n",
       "      <td>3.400994</td>\n",
       "      <td>3.308071</td>\n",
       "      <td>3.316595</td>\n",
       "      <td>3.499542</td>\n",
       "      <td>3.579876</td>\n",
       "      <td>3.308004</td>\n",
       "      <td>3.388554</td>\n",
       "      <td>3.407134</td>\n",
       "      <td>3.196367</td>\n",
       "      <td>3.625017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.406212</td>\n",
       "      <td>2.522759</td>\n",
       "      <td>2.532276</td>\n",
       "      <td>2.426052</td>\n",
       "      <td>2.392385</td>\n",
       "      <td>2.282347</td>\n",
       "      <td>2.322190</td>\n",
       "      <td>2.372856</td>\n",
       "      <td>2.003895</td>\n",
       "      <td>2.015269</td>\n",
       "      <td>...</td>\n",
       "      <td>2.338748</td>\n",
       "      <td>2.122675</td>\n",
       "      <td>2.333513</td>\n",
       "      <td>2.149856</td>\n",
       "      <td>2.112699</td>\n",
       "      <td>2.284969</td>\n",
       "      <td>2.175137</td>\n",
       "      <td>2.070347</td>\n",
       "      <td>2.441314</td>\n",
       "      <td>2.075735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unbiased_als [7, 7, 4, 40]  unbiased_als [10, 10, 4, 40]  \\\n",
       "0                    3.592601                      3.733556   \n",
       "1                    3.550760                      3.509360   \n",
       "2                    4.054709                      4.064456   \n",
       "3                    3.378575                      3.349753   \n",
       "4                    2.406212                      2.522759   \n",
       "\n",
       "   unbiased_als [12, 12, 4, 40]  unbiased_als [5, 5, 5, 40]  \\\n",
       "0                      3.696535                    3.532348   \n",
       "1                      3.487067                    3.521843   \n",
       "2                      4.011243                    4.147824   \n",
       "3                      3.378884                    3.397274   \n",
       "4                      2.532276                    2.426052   \n",
       "\n",
       "   unbiased_als [7, 7, 5, 40]  unbiased_als [10, 10, 5, 40]  \\\n",
       "0                    3.524818                      3.482530   \n",
       "1                    3.473323                      3.392697   \n",
       "2                    4.066299                      3.962364   \n",
       "3                    3.476615                      3.327078   \n",
       "4                    2.392385                      2.282347   \n",
       "\n",
       "   unbiased_als [12, 12, 5, 40]  unbiased_als [5, 5, 6, 40]  \\\n",
       "0                      3.491156                    3.534645   \n",
       "1                      3.396442                    3.519983   \n",
       "2                      3.932126                    4.117941   \n",
       "3                      3.353676                    3.401224   \n",
       "4                      2.322190                    2.372856   \n",
       "\n",
       "   unbiased_als [7, 7, 6, 40]  unbiased_als [10, 10, 6, 40]  ...  \\\n",
       "0                    3.923361                      3.909867  ...   \n",
       "1                    3.279215                      3.286031  ...   \n",
       "2                    4.062959                      4.031632  ...   \n",
       "3                    3.610752                      3.567498  ...   \n",
       "4                    2.003895                      2.015269  ...   \n",
       "\n",
       "   biased_als [8, 8, 3, 3]  biased_als [5, 5, 4, 4]  biased_als [6, 6, 3, 3]  \\\n",
       "0                 3.288667                 3.522192                 3.353738   \n",
       "1                 3.470855                 3.281536                 3.449982   \n",
       "2                 3.830440                 3.806959                 3.849735   \n",
       "3                 3.400994                 3.308071                 3.316595   \n",
       "4                 2.338748                 2.122675                 2.333513   \n",
       "\n",
       "   biased_als [10, 10, 4, 4]  biased_als [8, 8, 4, 4]  \\\n",
       "0                   3.714608                 3.701243   \n",
       "1                   3.391374                 3.388822   \n",
       "2                   3.903995                 3.892564   \n",
       "3                   3.499542                 3.579876   \n",
       "4                   2.149856                 2.112699   \n",
       "\n",
       "   ss_ials biased_als [4, 4, 3, 3]  ss_ials biased_als [4, 4, 4, 4]  \\\n",
       "0                         3.336324                         3.467200   \n",
       "1                         3.442233                         3.292226   \n",
       "2                         3.857864                         3.790467   \n",
       "3                         3.308004                         3.388554   \n",
       "4                         2.284969                         2.175137   \n",
       "\n",
       "   ss_ials biased_als [5, 5, 4, 4]  ss_ials biased_als [4, 4, 2, 2]  \\\n",
       "0                         3.649741                         3.841463   \n",
       "1                         3.300970                         3.492179   \n",
       "2                         3.829250                         4.021208   \n",
       "3                         3.407134                         3.196367   \n",
       "4                         2.070347                         2.441314   \n",
       "\n",
       "   ss_ials biased_als [7, 7, 5, 5]  \n",
       "0                         3.795175  \n",
       "1                         3.306232  \n",
       "2                         3.859430  \n",
       "3                         3.625017  \n",
       "4                         2.075735  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stacked.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Boosting***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_raw['Mark']\n",
    "X_train = train_stacked.values\n",
    "X_test = test_stacked.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min MSE -  0.8037962968773544 Min iter -  150 Cur MSE -  0.8038294971316187\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 379/500 [31:20<10:36,  5.26s/it]"
     ]
    }
   ],
   "source": [
    "bagging = []\n",
    "prediction = np.zeros_like(y_train).astype(float)\n",
    "s1 = set(np.arange(0, y_train.shape[0]))\n",
    "norms = np.zeros_like(prediction).astype(float) + 1e-100\n",
    "mses = []\n",
    "estimators = []\n",
    "for i in tqdm.tqdm(range(500)):\n",
    "    index_bagg = np.random.randint(low=0, high=y_train.shape[0], size=y_train.shape[0])\n",
    "    #print(y_train.shape[0])\n",
    "    #print(X_train.shape[0])\n",
    "    X_bagg = X_train[index_bagg]\n",
    "    y_bagg = y_train[index_bagg]\n",
    "    #print(X_bagg.shape[0])\n",
    "    \n",
    "    lgbm = LGBMRegressor(n_estimators=400, learning_rate=0.05, max_depth=4, num_leaves=100)\n",
    "    #lgbm = CatBoostRegressor(n_estimators=200, learning_rate=0.05, max_depth=4, verbose=False, task_type='GPU')\n",
    "    lgbm.fit(X_bagg, y_bagg)\n",
    "    s2 = set(index_bagg)\n",
    "    out_of_bag = list(s1 - s2)\n",
    "    X_oub = X_train[out_of_bag]\n",
    "    prediction[out_of_bag] += lgbm.predict(X_oub)\n",
    "    norms[out_of_bag] += 1.0\n",
    "    mses.append(mean_squared_error(prediction/norms, y_train))\n",
    "    estimators.append(lgbm)\n",
    "    if i % 20 == 0 and i != 0:\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.plot(mses)\n",
    "        print('Min MSE - ', np.min(mses), 'Min iter - ', np.argmin(mses), 'Cur MSE - ', mses[-1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.zeros(len(test_stacked.index))\n",
    "for estim in estimators:\n",
    "    prediction += estim.predict(test_stacked.values)\n",
    "prediction /= len(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = pd.DataFrame()\n",
    "test_prediction['Id'] = np.arange(1, len(prediction) + 1)\n",
    "test_prediction['Score'] = prediction\n",
    "test_prediction['Id'] = np.arange(1, len(prediction) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
